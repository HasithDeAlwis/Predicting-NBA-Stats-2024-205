{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d8bc062-b7a2-4b23-9293-f74860cbe5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1ba6f6-9f5c-4eff-9911-e2f774383665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathFunctions:\n",
    "    \"\"\"\n",
    "    Calculated the variance of the target variable in a pandas dataframe\n",
    "    df: dataframe that we will evaluvate\n",
    "    return: float that represents the variance\"\"\"\n",
    "    def calc_variance(df: pd.DataFrame) -> float:\n",
    "        #var of target variables\n",
    "        return df['target'].var()\n",
    "        \n",
    "    \"\"\"\n",
    "    Evaluvate how much info we have gained from a split\n",
    "    left_child_df: the left child of a node\n",
    "    right_child_df: the right child of a node\n",
    "    return: the variance difference between the current variance the the avg of the two variances\"\"\"\n",
    "    @staticmethod\n",
    "    def calc_variance_reduction(left_child_df: pd.DataFrame, right_child_df: pd.DataFrame):\n",
    "        #the weight just represents the portion that each child takes up relative to the size of the original node\n",
    "        weight = float( len(left_child_df) / (len(left_child_df) + len(right_child_df)))\n",
    "        #the split_variance is the sum of both variances, the lower this number is, the better\n",
    "        split_variance = weight * MathFunctions.calc_variance(left_child_df) + (1-weight) * MathFunctions.calc_variance(right_child_df)\n",
    "        return split_variance\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae923cb-1125-4ec5-834e-4d7e3548751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A class to hold the questions used to evaluate a decision tree\n",
    "class Question:\n",
    "    #initialize the variables\n",
    "    def __init__(self, column: str, value: float):\n",
    "        \"\"\"\n",
    "        Column stores what is the feature we are analyzing\n",
    "        Value is the numeric value that will be compared\n",
    "        ie. if column is 'PTS' and value is 12.4 the question is asking, is \"PTS <= 12.4?\"? \"\"\"\n",
    "        self.column = column \n",
    "        self.value = value\n",
    "        \n",
    "    \"\"\"\n",
    "    A function that will give us the condition we are checking - useful for pandas when querrying a data frame\n",
    "    return a string that is the condition we are comparing\n",
    "    \"\"\"\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.column} <= {self.value}\"\n",
    "        \n",
    "    def checkTrueCondition(self, row) -> str:\n",
    "        if row[column] <= value:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ac07e2-9b7a-43b1-a5f2-50d69293ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Leaf class is what holds the possible predictions of an input\"\"\"\n",
    "class Leaf:\n",
    "    #initialize the variables\n",
    "    def __init__(self, targets: pd.DataFrame):\n",
    "        #targets are all of the predictions given going down a tree\n",
    "        #target is a list of predictions\n",
    "        self.targets = targets \n",
    "    \"\"\"\n",
    "    Find the average of all targets\n",
    "    return: average of the list of predictions, self.targets\n",
    "    \"\"\"\n",
    "    def calcPrediction(self, min, max) -> float:\n",
    "        return self.targets['target'].mean() * (max - min) + min\n",
    "        \n",
    "    def calcPrediction_2(self) -> float:\n",
    "        return self.targets['target'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a55b665-4f89-4029-b4f9-a85c05788bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Node class is what represents a decision in our decision tree\n",
    "It keeps track of the question and the paritions following the question\n",
    "\"\"\"\n",
    "class Node:\n",
    "    #initialize variables\n",
    "    \"\"\"\n",
    "    question: the question that will cause the paritions (left child, right child)\n",
    "    true: represents the right child, which is the true partition\n",
    "    false: represents the left child, which is the false partition\n",
    "    \"\"\"\n",
    "    def __init__(self, question: Question, true: pd.DataFrame, false: pd.DataFrame):\n",
    "        self.question = question\n",
    "        self.true = true\n",
    "        self.false = false\n",
    "\n",
    "    \"\"\"\n",
    "    A function that will take in a newVal to compare with self.question\n",
    "    newVal: a value that will be used to compare against self.question\n",
    "    return: True is if newVal is less than or equal to the question value, \n",
    "    False is if newVal is greater than the question value\n",
    "    \"\"\"\n",
    "    def makeDecision(self, newVal: float) -> bool:\n",
    "        #checkTrue compares a newVal with the question\n",
    "        return self.question.checkTrue(newVal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0426a0-79d2-4db4-bb3e-7b165e3e98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Partitions class is what splits the data and analyzes the best split for two split dataframes\n",
    "\"\"\"\n",
    "class Partitions:\n",
    "    \"\"\"\n",
    "    A function that will return a divided version of the curDF based on the question\n",
    "    curDF: original Pandas DF that will be split\n",
    "    question: a question that will be used to split the curDF\n",
    "    return: a dataframe where the question is evaluvated to true and another where the question is evaluvated to false\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def partition(question: Question, curDF: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "        #split the data based on the value and the column analyzed\n",
    "        true_df = curDF[curDF[question.column] <= question.value]\n",
    "        false_df = curDF[curDF[question.column] > question.value]  # > is the negation of <=\n",
    "        #return the two data frames\n",
    "        return true_df, false_df\n",
    "\n",
    "    \"\"\"\n",
    "    A function that will determine the question that will give us the best partition\n",
    "    df: the dataframe that will be analyzed to determine the best partition\n",
    "    return: the best question question and the variance of the best question\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def bestPartition(df: pd.DataFrame) -> (float, Question):\n",
    "        #set the smallest variance to a very high number intitially - since data is scaled it is impossible to get over 1000000 variance\n",
    "        smallest_variance = 10000000\n",
    "        #set the cur smallest variance to this\n",
    "        Partitions.findSmallestVariance.smallest_variance = smallest_variance\n",
    "        #loop through every column\n",
    "        for col in df.columns:\n",
    "            if col == 'target':\n",
    "                continue\n",
    "            #apply the method that finds the smallest variance in a column\n",
    "            df[col].apply(lambda value: Partitions.findSmallestVariance(col, value, df))\n",
    "        #return the smallest variances and the best question\n",
    "        return Partitions.findSmallestVariance.smallest_variance, Partitions.findSmallestVariance.best_question\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    A function that compares the variance of a split with the current smallest variance of a split\n",
    "    column: the column of the value being analyzed\n",
    "    value: the numerical value \n",
    "    df: the dataframe that will be analyzed to determine the best partition\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def findSmallestVariance(column: str, value: float, df: pd.DataFrame):\n",
    "        question = Question(column, value)\n",
    "        true_rows, false_rows = Partitions.partition(question, df)\n",
    "        if len(false_rows) == 0 or len(true_rows) == 0:\n",
    "            current_weighted_variance = MathFunctions.calc_variance(df)\n",
    "        else:\n",
    "            current_weighted_variance = MathFunctions.calc_variance_reduction(true_rows, false_rows)\n",
    "\n",
    "        if current_weighted_variance < Partitions.findSmallestVariance.smallest_variance:\n",
    "            # Update the minimum weighted variance if necessary\n",
    "            Partitions.findSmallestVariance.smallest_variance = current_weighted_variance\n",
    "            Partitions.findSmallestVariance.best_question = question\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "717cc22b-2faa-4c9e-b0f1-2293b2c1d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Tree class is what actually builds the tree and hold the instance of a deicison tree\n",
    "\"\"\"\n",
    "class Tree:\n",
    "    \"\"\"\n",
    "    originalData: the data that is intially given to the tree\n",
    "    root: the first decision node\"\"\"\n",
    "    def __init__(self, originalData: pd.DataFrame, max, min, root = None):\n",
    "        self.max = max\n",
    "        self.min = min\n",
    "        self.root = root\n",
    "        self.data = originalData\n",
    "    \"\"\"\n",
    "    A function that will build the tree\n",
    "    curDepth: the depth that the tree is currently at -> int\n",
    "    data: the dataset to be analyzed at the current moment -> \n",
    "    maxDepth: to prevent overfitting we have a maxDepth of 4\n",
    "    return: recursively return the Node or Leaf that is the result of a branch in the decision tree\n",
    "    \"\"\"\n",
    "    def build_tree(self, curDepth = None, data=None, maxDepth = 4) -> Node or Leaf:\n",
    "        #check to see if data is an instance of the dataframe to ensure it is not none\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            #if it is none, make the data equal the original data\n",
    "            data = self.data\n",
    "        #set curDepth to 0 on the first loop\n",
    "        if curDepth == None:\n",
    "            curDepth = 0\n",
    "        #get the best variance and best paritition\n",
    "        variance, question = Partitions.bestPartition(data)\n",
    "        if variance == 0 or curDepth == maxDepth:\n",
    "            #we are at the last recursion so we return a Leaf that is the result of a branch\n",
    "            return Leaf(data) #data represents the possible options that arrise from a decision tree\n",
    "            \n",
    "        #get the true and false data based on the best question and current data we have\n",
    "        true, false = Partitions.partition(question, data)\n",
    "        \n",
    "        #now recusrively build the true branch based on the true partition\n",
    "        true_branch = self.build_tree(data=true, curDepth = curDepth+1) \n",
    "        #now recursively build the false branch based on the false partition\n",
    "        false_branch = self.build_tree(data=false, curDepth = curDepth + 1)\n",
    "        \n",
    "        #if we get to here and curDepth is 0, that means we are done building the tree\n",
    "        if curDepth == 0:\n",
    "            #assign the last node to be the root\n",
    "            self.root = Node(question, true_branch, false_branch)\n",
    "            #return the root\n",
    "            return self.root\n",
    "        \n",
    "        #return a decision node that contains the question it asked and the true and false branch\n",
    "        return Node(question, true_branch, false_branch)\n",
    "    \n",
    "    def print_tree(self, node = None, spacing=\"\"): \n",
    "        if node == None:\n",
    "            node = self.root\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, Leaf):\n",
    "            prediction = node.calcPrediction(self.min, self.max)\n",
    "            print (spacing + \"Predict\", prediction)\n",
    "            return\n",
    "    \n",
    "        # Print the question at this node\n",
    "        print (spacing + str(node.question))\n",
    "    \n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.print_tree(node.true, spacing + \"  \")\n",
    "    \n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.print_tree(node.false, spacing + \"  \")\n",
    "    def classify(self, row):\n",
    "        predicting_row = pd.DataFrame()\n",
    "        curNode = self.root\n",
    "        while isinstance(curNode, Node):\n",
    "            if curNode.checkTrueCondition(row):\n",
    "                curNode = curNode.true\n",
    "            else:\n",
    "                curNode = curNode.false\n",
    "                \n",
    "        return curNode.calcPrediction_2()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff7b72c5-52e3-4fe4-9d2c-569760c4adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Forest class contains all the trees\n",
    "\"\"\"\n",
    "class Forest:\n",
    "    #intialize a forest, with no trees at first\n",
    "    def __init__(self, dataSet: pd.DataFrame, min, max):\n",
    "        self.max_value = max\n",
    "        self.min_value = min\n",
    "        \n",
    "        self.dataSet = dataSet\n",
    "        self.trees = []\n",
    "\n",
    "    #bootstrapping is a technique in ML that randomly takes rows from the training data to train the dataset\n",
    "    def bootStrapping(self, n):\n",
    "        random_indicies = np.random.randint(low=0, high=len(self.dataSet), size = n)\n",
    "        return random_indicies\n",
    "\n",
    "    def randomSubspace(self, n):\n",
    "        target = 'target'\n",
    "        random_columns = self.dataSet.columns[self.dataSet.columns != target].to_series().sample(n=9, random_state=42)\n",
    "        selectedColumns = random_columns.tolist() + [target]\n",
    "        return selectedColumns\n",
    "\n",
    "    def random_dataset(self, numRows, numCol):\n",
    "        random_indicies = self.bootStrapping(numRows)\n",
    "        random_columns = self.randomSubspace(numCol)\n",
    "        randomized_data = self.dataSet.iloc[random_indicies][random_columns]\n",
    "        return randomized_data\n",
    "\n",
    "    def createTree(self, numRows, numCol):\n",
    "        random_dataset = self.random_dataset(numRows, numCol)\n",
    "        tree = Tree(random_dataset, self.max_value, self.min_value)\n",
    "        tree.build_tree()\n",
    "        tree.print_tree()\n",
    "        self.trees.append(tree)\n",
    "\n",
    "    def createForest(self, n, numRows=500, numCol=12):\n",
    "        for i in range(n):\n",
    "            self.createTree(numRows, numCol)\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        predictions = test_df.apply(lambda row: make_prediction(row), axis=1)\n",
    "        return predictions \n",
    "        \n",
    "    def make_predictions(self, row):\n",
    "        prediction_sum = 0\n",
    "        for tree in self.trees:\n",
    "            prediction_sum += tree.classify(row)\n",
    "        return prediction_sum/len(self.trees)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcc7c02-2c11-4ab0-977c-e6743e7a2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to shift values for a specific player\n",
    "def shift_player_points(group, target):\n",
    "    group['target'] = group[target].shift(-1)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a3ee4c-22ba-4cc1-a44e-d74d3ccb3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min(df: pd.DataFrame, targetVar):\n",
    "    return df[targetVar].min(), df[targetVar].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0631d0cb-1218-456b-82eb-395c1455fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setTarget(data: pd.DataFrame):\n",
    "    #get rid of unecessary column\n",
    "    data.drop(\"Unnamed: 0\", axis=\"columns\")\n",
    "    # Apply the shifting function within each player group\n",
    "    df_shifted = data.groupby('ID').apply(lambda x: shift_player_points(x, 'PTS')).copy()\n",
    "\n",
    "    #make everything sorted by the season\n",
    "    df_shifted[['StartYear', 'EndYear']] = df_shifted['Season'].str.split('-', expand=True).copy()\n",
    "    df_shifted['StartYear'] = pd.to_datetime(df_shifted['StartYear'], format='%Y').copy()\n",
    "    df_final  = df_shifted.sort_values(by='StartYear')\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bba9b239-7ef5-4f52-bff3-180ea48a2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df):\n",
    "    #drop all the columns except for the numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "\n",
    "    #get the max and min\n",
    "    min, max = get_max_min(df, 'PTS')\n",
    "    \n",
    "    #intialize the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    #scale the data for ML\n",
    "    df_scaled[numeric_columns] = scaler.fit_transform(df[numeric_columns]).copy()\n",
    "    \n",
    "    #get rid of any NA values\n",
    "    df_scaled = df_scaled.dropna()\n",
    "    \n",
    "    #only take numeric columns\n",
    "    df_final = df_scaled[numeric_columns]\n",
    "    df_final = df_final.drop(\"Unnamed: 0\", axis=\"columns\").copy()\n",
    "    \n",
    "    return df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cad0b49-78a6-4b0f-8793-a856c0cefb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesting(df):\n",
    "    # Initial threshold datetime set to 2006, so that we can have atleast three years of data before we start predicting\n",
    "    threshold_date = datetime(2006, 1, 1)\n",
    "    \n",
    "    #last season where we can train our model\n",
    "    end_date = datetime(2022, 1, 1)\n",
    "\n",
    "    df_prep = setTarget(df)\n",
    "    all_predictions = []\n",
    "    while threshold_date != end_date:\n",
    "        #train the data using every stat before the year\n",
    "        train = df_prep[df_prep['StartYear'] <= threshold_date]\n",
    "        \n",
    "        #make predictions on the current year using previous data\n",
    "        test = df[df['StartYear'] == threshold_date]\n",
    "\n",
    "        #scale the data so that we can train it adequately with the model\n",
    "        \n",
    "        #very important for random forest since we use variation regretion to make decisions\n",
    "        ready_training_df, min, max = scaleData(train)\n",
    "        \n",
    "        forest = Forest(ready_training_df, min, max)\n",
    "        \n",
    "        forest.createForest(100)\n",
    "\n",
    "        predictions = forest.predict(test)\n",
    "        all_prediciton.append(predictions)\n",
    "        \n",
    "        return train, test\n",
    "    return all_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8183fca7-c92a-4792-8b88-191a0787d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_main():\n",
    "    # Create a sample DataFrame\n",
    "    data = nba_player_stats = pd.read_csv(\"all_players_stats.csv\")\n",
    "    backtesting(data)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd023f08-819e-4f45-8c52-a2c24c7526a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_backtesting():\n",
    "    df = pd.read_csv(\"all_players_stats.csv\")\n",
    "    train, test = backtesting(df)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05136f18-568e-4e02-9d64-2ac9703aec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>teamPPG</th>\n",
       "      <th>oppPPG</th>\n",
       "      <th>SRS</th>\n",
       "      <th>pace</th>\n",
       "      <th>teamOFRtg</th>\n",
       "      <th>teamDFRtg</th>\n",
       "      <th>target</th>\n",
       "      <th>StartYear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>owarjo01</th>\n",
       "      <th>728</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.546988</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.322449</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.393795</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.734317</td>\n",
       "      <td>0.349030</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diawbo01</th>\n",
       "      <th>1316</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.585542</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.167347</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533546</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.176190</td>\n",
       "      <td>0.315036</td>\n",
       "      <td>0.354010</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.372694</td>\n",
       "      <td>0.132964</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barnema02</th>\n",
       "      <th>4517</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.436145</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534611</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.223810</td>\n",
       "      <td>0.360382</td>\n",
       "      <td>0.403793</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.299639</td>\n",
       "      <td>0.376384</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barbole01</th>\n",
       "      <th>1026</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.491566</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549521</td>\n",
       "      <td>0.181159</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.324582</td>\n",
       "      <td>0.435401</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.223827</td>\n",
       "      <td>0.413284</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udokaim01</th>\n",
       "      <th>2729</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.093878</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504792</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.238663</td>\n",
       "      <td>0.723429</td>\n",
       "      <td>0.322751</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.715867</td>\n",
       "      <td>0.077562</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varejan01</th>\n",
       "      <th>4385</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.551807</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558040</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.205251</td>\n",
       "      <td>0.683129</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.715867</td>\n",
       "      <td>0.185596</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smithcr01</th>\n",
       "      <th>857</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.426506</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538871</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.254762</td>\n",
       "      <td>0.367542</td>\n",
       "      <td>0.426709</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.314079</td>\n",
       "      <td>0.413284</td>\n",
       "      <td>0.260388</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brewero02</th>\n",
       "      <th>1619</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.267470</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.138776</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570820</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.341289</td>\n",
       "      <td>0.672461</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.537906</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.332410</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arizatr01</th>\n",
       "      <th>1369</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.515663</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.223810</td>\n",
       "      <td>0.231504</td>\n",
       "      <td>0.565389</td>\n",
       "      <td>0.195767</td>\n",
       "      <td>0.350181</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>willima01</th>\n",
       "      <th>479</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.853012</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552716</td>\n",
       "      <td>0.210145</td>\n",
       "      <td>0.340476</td>\n",
       "      <td>0.470167</td>\n",
       "      <td>0.376531</td>\n",
       "      <td>0.322751</td>\n",
       "      <td>0.425993</td>\n",
       "      <td>0.387454</td>\n",
       "      <td>0.476454</td>\n",
       "      <td>2006-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AGE         G        GS        MP        FG       FGA  \\\n",
       "ID                                                                           \n",
       "owarjo01  728   0.208333  0.804878  0.349398  0.546988  0.290598  0.322449   \n",
       "diawbo01  1316  0.125000  0.914634  0.445783  0.585542  0.153846  0.167347   \n",
       "barnema02 4517  0.208333  0.451220  0.108434  0.436145  0.145299  0.146939   \n",
       "barbole01 1026  0.125000  0.841463  0.554217  0.491566  0.256410  0.273469   \n",
       "udokaim01 2729  0.333333  0.036585  0.000000  0.144578  0.068376  0.093878   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "varejan01 4385  0.250000  0.975610  0.072289  0.551807  0.205128  0.204082   \n",
       "smithcr01 857   0.208333  0.987805  0.060241  0.426506  0.256410  0.228571   \n",
       "brewero02 1619  0.125000  0.670732  0.168675  0.267470  0.153846  0.138776   \n",
       "arizatr01 1369  0.125000  0.682927  0.084337  0.515663  0.299145  0.265306   \n",
       "willima01 479   0.250000  0.817073  0.819277  0.853012  0.589744  0.628571   \n",
       "\n",
       "                  FG%        3P       3PA    3P%  ...       BPM      VORP  \\\n",
       "ID                                                ...                       \n",
       "owarjo01  728   0.430  0.056604  0.075758  0.303  ...  0.556976  0.202899   \n",
       "diawbo01  1316  0.447  0.018868  0.022727  0.231  ...  0.533546  0.130435   \n",
       "barnema02 4517  0.457  0.018868  0.022727  0.154  ...  0.534611  0.144928   \n",
       "barbole01 1026  0.447  0.226415  0.227273  0.395  ...  0.549521  0.181159   \n",
       "udokaim01 2729  0.333  0.000000  0.022727  0.000  ...  0.504792  0.144928   \n",
       "...               ...       ...       ...    ...  ...       ...       ...   \n",
       "varejan01 4385  0.476  0.000000  0.007576  0.000  ...  0.558040  0.217391   \n",
       "smithcr01 857   0.531  0.000000  0.007576  0.000  ...  0.538871  0.152174   \n",
       "brewero02 1619  0.528  0.000000  0.015152  0.000  ...  0.570820  0.188406   \n",
       "arizatr01 1369  0.539  0.000000  0.007576  0.000  ...  0.575080  0.231884   \n",
       "willima01 479   0.446  0.226415  0.257576  0.346  ...  0.552716  0.210145   \n",
       "\n",
       "                 teamPPG    oppPPG       SRS      pace  teamOFRtg  teamDFRtg  \\\n",
       "ID                                                                             \n",
       "owarjo01  728   0.471429  0.393795  0.743580  0.370370   0.610108   0.734317   \n",
       "diawbo01  1316  0.176190  0.315036  0.354010  0.243386   0.209386   0.372694   \n",
       "barnema02 4517  0.223810  0.360382  0.403793  0.253968   0.299639   0.376384   \n",
       "barbole01 1026  0.209524  0.324582  0.435401  0.338624   0.223827   0.413284   \n",
       "udokaim01 2729  0.304762  0.238663  0.723429  0.322751   0.371841   0.715867   \n",
       "...                  ...       ...       ...       ...        ...        ...   \n",
       "varejan01 4385  0.271429  0.205251  0.683129  0.243386   0.371841   0.715867   \n",
       "smithcr01 857   0.254762  0.367542  0.426709  0.253968   0.314079   0.413284   \n",
       "brewero02 1619  0.383333  0.341289  0.672461  0.285714   0.537906   0.675277   \n",
       "arizatr01 1369  0.223810  0.231504  0.565389  0.195767   0.350181   0.594096   \n",
       "willima01 479   0.340476  0.470167  0.376531  0.322751   0.425993   0.387454   \n",
       "\n",
       "                  target  StartYear  \n",
       "ID                                   \n",
       "owarjo01  728   0.349030 2003-01-01  \n",
       "diawbo01  1316  0.132964 2003-01-01  \n",
       "barnema02 4517  0.105263 2003-01-01  \n",
       "barbole01 1026  0.193906 2003-01-01  \n",
       "udokaim01 2729  0.077562 2003-01-01  \n",
       "...                  ...        ...  \n",
       "varejan01 4385  0.185596 2006-01-01  \n",
       "smithcr01 857   0.260388 2006-01-01  \n",
       "brewero02 1619  0.332410 2006-01-01  \n",
       "arizatr01 1369  0.152355 2006-01-01  \n",
       "willima01 479   0.476454 2006-01-01  \n",
       "\n",
       "[375 rows x 99 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_backtesting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c04bfb90-fb75-4e58-9828-586a64e007d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2P <= 0.45132743362831856\n",
      "--> True:\n",
      "  2P <= 0.1946902654867257\n",
      "  --> True:\n",
      "    2P <= 0.09734513274336284\n",
      "    --> True:\n",
      "      2P <= 0.02654867256637168\n",
      "      --> True:\n",
      "        Predict 0.925\n",
      "      --> False:\n",
      "        Predict 5.020754716981132\n",
      "    --> False:\n",
      "      TOV% <= 0.14400000000000002\n",
      "      --> True:\n",
      "        Predict 7.830232558139536\n",
      "      --> False:\n",
      "        Predict 5.437931034482758\n",
      "  --> False:\n",
      "    OWS <= 0.24861878453038672\n",
      "    --> True:\n",
      "      STL_100 <= 0.2990654205607477\n",
      "      --> True:\n",
      "        Predict 9.864444444444446\n",
      "      --> False:\n",
      "        Predict 0.7\n",
      "    --> False:\n",
      "      TRB_100 <= 0.17680608365019013\n",
      "      --> True:\n",
      "        Predict 14.22325581395349\n",
      "      --> False:\n",
      "        Predict 10.114285714285714\n",
      "--> False:\n",
      "  2P <= 0.6106194690265487\n",
      "  --> True:\n",
      "    TRB_100 <= 0.35551330798479086\n",
      "    --> True:\n",
      "      OWS <= 0.34806629834254144\n",
      "      --> True:\n",
      "        Predict 15.51\n",
      "      --> False:\n",
      "        Predict 20.65833333333333\n",
      "    --> False:\n",
      "      Predict 8.1\n",
      "  --> False:\n",
      "    STL_100 <= 0.14953271028037385\n",
      "    --> True:\n",
      "      TRB_100 <= 0.1730038022813688\n",
      "      --> True:\n",
      "        Predict 25.46\n",
      "      --> False:\n",
      "        Predict 20.54615384615385\n",
      "    --> False:\n",
      "      DRB_36 <= 0.16666666666666666\n",
      "      --> True:\n",
      "        Predict 29.9\n",
      "      --> False:\n",
      "        Predict 25.950000000000003\n"
     ]
    }
   ],
   "source": [
    "forest = testing_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64ddc1-0a5a-461b-b412-1cc5b1e05a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

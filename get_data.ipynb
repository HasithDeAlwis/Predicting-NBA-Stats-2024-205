{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7aab27-ab51-492d-8228-5ff23855f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36f7ca3-8049-4f7d-b457-5a968ba1a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create directory for all files that will store data\n",
    "DATA_DIR = \"data\"\n",
    "PLAYER_NAMES_DIR = os.path.join(DATA_DIR, 'player_names')\n",
    "PLAYER_STATS_DIR = os.path.join(DATA_DIR, 'player_stats')\n",
    "PLAYER_STATS_2_DIR = os.path.join(DATA_DIR, 'player_stats_2')\n",
    "NBA_TEAM_STATS = os.path.join(DATA_DIR, 'nba_team_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5b9175-b0d5-4e23-ad15-0a9cf952de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will scrape an html page given a couple selectors\n",
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    html = None\n",
    "    #retries is how many times we will try to scrape html off a page\n",
    "    for i in range(1, retries+1):\n",
    "        #use sleep so that a webpage doesn't ban us for constant attempts at scraping their page\n",
    "        time.sleep(sleep * i)\n",
    "        try:\n",
    "            #using playwright open a browser and analyze a page\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.firefox.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                #only take the inner_html that have our desired selectors\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            #exit if there is a timeout error\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            #no need to try again if we are successfull\n",
    "            break\n",
    "    #return the html code of our desired webpage\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e12d4d-da34-4afb-84f3-208f0d9fa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that scrapes that tables of all players\n",
    "async def scrape_names():\n",
    "    #go to players page\n",
    "    url = \"https://www.basketball-reference.com/players/\"\n",
    "    #get the alphabet and links from the alaphabet in the site\n",
    "    html = await get_html(url, \"#div_alphabet\")\n",
    "\n",
    "    #find anchor tags that link to the page \n",
    "    soup = BeautifulSoup(html)\n",
    "    #get the names\n",
    "    links = soup.find_all(\"a\")\n",
    "    #get the link for said name\n",
    "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
    "    #save the html to the file for later data parsing\n",
    "    for url in standings_pages:\n",
    "        #get the path \n",
    "        save_path = os.path.join(PLAYER_NAMES_DIR, \"last_name_\" + url.split(\"/\")[-2])\n",
    "        #dont add the page if it already exists\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        #grab the html of the page and write it to the file\n",
    "        html = await get_html(url, \"#players\")\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cbef3d-cf14-4f0d-9a05-1d49c7c4d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a function that will choose which players actually get slected for the project\n",
    "def scrape_table(letter):\n",
    "    #get all the links for the tables in one page onto an array\n",
    "    linksForTables = []\n",
    "    #get the path that holds the names for all the players of a specific letter\n",
    "    playersTable = os.path.join(PLAYER_NAMES_DIR, NAMES_FILES[letter])\n",
    "    #read the html\n",
    "    with open(playersTable, 'r') as f:\n",
    "        html = f.read()\n",
    "    #using beautiful soup analyze the body of the page\n",
    "    soup = BeautifulSoup(html)\n",
    "    soup = soup.find(\"tbody\")\n",
    "    #get the rows of the table that contain the player names\n",
    "    allPlayers = soup.find_all(\"tr\")\n",
    "    #for each player check certain attributes to deem whether or not we will use it\n",
    "    for player in allPlayers:\n",
    "        playerLink = \"\"\n",
    "        #get the starting date\n",
    "        startingYear = player.find(attrs={'data-stat': 'year_min'}).text\n",
    "        #sometimes this will be \"From\", igore if the start date is from and move to next row\n",
    "        if startingYear == \"From\":\n",
    "            continue #moving to next row\n",
    "        #find the year the player joined the table\n",
    "        start_year = int(player.find(attrs={'data-stat':'year_min'}).text)\n",
    "        end_year = int(player.find(attrs={'data-stat':'year_max'}).text)\n",
    "        if  start_year >= 2005 and end_year - start_year >= 5:\n",
    "            name = player.find(attrs={'data-stat':'player'})\n",
    "            playerLink = name.find(\"a\")['href']\n",
    "            playerLink = \"https://www.basketball-reference.com\" + playerLink\n",
    "            linksForTables.append(playerLink)\n",
    "    return linksForTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44409be-9b1e-458f-8995-5a2bdce2df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_scrape_table(letter):\n",
    "    #get all the links for the tables in one page onto an array\n",
    "    linksForTables = []\n",
    "    #get the path that holds the names for all the players of a specific letter\n",
    "    playersTable = os.path.join(PLAYER_NAMES_DIR, NAMES_FILES[letter])\n",
    "    #read the html\n",
    "    with open(playersTable, 'r') as f:\n",
    "        html = f.read()\n",
    "    #using beautiful soup analyze the body of the page\n",
    "    soup = BeautifulSoup(html)\n",
    "    soup = soup.find(\"tbody\")\n",
    "    #get the rows of the table that contain the player names\n",
    "    allPlayers = soup.find_all(\"tr\")\n",
    "    #for each player check certain attributes to deem whether or not we will use it\n",
    "    for player in allPlayers:\n",
    "        playerLink = \"\"\n",
    "        #get the starting date\n",
    "        startingYear = player.find(attrs={'data-stat': 'year_min'}).text\n",
    "        #sometimes this will be \"From\", igore if the start date is from and move to next row\n",
    "        if startingYear == \"From\":\n",
    "            continue #moving to next row\n",
    "        #find the year the player joined the table\n",
    "        start_year = int(player.find(attrs={'data-stat':'year_min'}).text)\n",
    "        end_year = int(player.find(attrs={'data-stat':'year_max'}).text)\n",
    "        if  start_year == 2004 and end_year - start_year >= 5:\n",
    "            name = player.find(attrs={'data-stat':'player'})\n",
    "            playerLink = name.find(\"a\")['href']\n",
    "            playerLink = \"https://www.basketball-reference.com\" + playerLink\n",
    "            linksForTables.append(playerLink)\n",
    "    return linksForTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1d5d22-c2a0-4cf6-bccd-e087ff27d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_career_stats(player_url):\n",
    "    html = await get_html(player_url, \"#wrap\")\n",
    "    \n",
    "    if html != None: \n",
    "        soup = BeautifulSoup(html)\n",
    "        per_game = soup.find(id=\"div_per_game\")\n",
    "        playerTeams = []\n",
    "        team_ids = per_game.find_all(attrs={\"data-stat\":'team_id'})\n",
    "        for team_id in team_ids:\n",
    "            link = team_id.find(\"a\")\n",
    "            if (link):\n",
    "                playerTeams.append(link['href'])\n",
    "        print(playerTeams)\n",
    "        team_link = soup.find(\"a\")['href']\n",
    "        name = player_url.split('/')[-1]\n",
    "        save_path = os.path.join(PLAYER_STATS_2_DIR, name)\n",
    "        if not os.path.exists(save_path):\n",
    "            with open(save_path, \"w+\") as f:\n",
    "                f.write(html)\n",
    "        return playerTeams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407b970e-bba5-4dcc-9f78-3609b2489940",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_nba_team_stats(team_url):\n",
    "    #split the url\n",
    "    split_url = team_url.split(\"/\")\n",
    "    #make the name of the file based on the team name + year\n",
    "    name = split_url[4] + split_url[5]\n",
    "    #get the path\n",
    "    print(\"Current Team: \", name)\n",
    "    save_path = os.path.join(NBA_TEAM_STATS, name)\n",
    "    #check to see if the path exists\n",
    "    if not os.path.exists(save_path):\n",
    "        #if it does, then get the html\n",
    "        html = await get_html(team_url, \"#wrap\")\n",
    "        if html != None:\n",
    "                with open(save_path, \"w+\") as f:\n",
    "                    f.write(html)\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94762a8b-bbe2-4872-aabb-0849e64c7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NBA_team_link():\n",
    "    #GET THE LINKS TO EVERY SINGLE NBA TEAM FROM 2005 to 2014\n",
    "    NBA_TEAMS = [\n",
    "        \"ATL\",  # Atlanta Hawks\n",
    "        \"BOS\",  # Boston Celtics\n",
    "        \"CHI\",  # Chicago Bulls\n",
    "        \"CLE\",  # Cleveland Cavaliers\n",
    "        \"DAL\",  # Dallas Mavericks\n",
    "        \"DEN\",  # Denver Nuggets\n",
    "        \"DET\",  # Detroit Pistons\n",
    "        \"GSW\",  # Golden State Warriors\n",
    "        \"HOU\",  # Houston Rockets\n",
    "        \"IND\",  # Indiana Pacers\n",
    "        \"LAC\",  # LA Clippers\n",
    "        \"LAL\",  # Los Angeles Lakers\n",
    "        \"MEM\",  # Memphis Grizzlies\n",
    "        \"MIA\",  # Miami Heat\n",
    "        \"MIL\",  # Milwaukee Bucks\n",
    "        \"MIN\",  # Minnesota Timberwolves\n",
    "        \"NYK\",  # New York Knicks\n",
    "        \"ORL\",  # Orlando Magic\n",
    "        \"PHI\",  # Philadelphia 76ers\n",
    "        \"PHO\",  # Phoenix Suns\n",
    "        \"POR\",  # Portland Trail Blazers\n",
    "        \"SAC\",  # Sacramento Kings\n",
    "        \"SAS\",  # San Antonio Spurs\n",
    "        \"TOR\",  # Toronto Raptors\n",
    "        \"UTA\",  # Utah Jazz\n",
    "        \"WAS\",  # Washington Wizards\n",
    "    ]\n",
    "    #add all the links to the array\n",
    "    teamLinks = []\n",
    "    for nba_team in NBA_TEAMS:\n",
    "        for i in range(2004, 2025):\n",
    "            teamLinks.append(f'https://www.basketball-reference.com/teams/{nba_team}/{i}.html')\n",
    "    \n",
    "    #Charlote Hornets/Bobcats are an exception b/c their team changed mascots in the 2015-2016 season the bobcats became the hornets\n",
    "    for i in range(2004, 2015):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/CHA/{i}.html\")\n",
    "    for i in range(2015, 2025):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/CHO/{i}.html\") \n",
    "\n",
    "    #New Orlean Pelicans/Hornets are another exception that changed franchise names in the 2012-2013 season\n",
    "    for i in range(2004, 2014):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/NOH/{i}.html\")\n",
    "    for i in range(2006, 2008):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/NOK/{i}.html\")\n",
    "    for i in range(2014, 2025):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/NOP/{i}.html\")\n",
    "\n",
    "    #Seattle Supersonics changed cities to become the OKC Thunder in 2009 so they are another exception\n",
    "    for i in range(2004, 2009):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/SEA/{i}.html\")\n",
    "    for i in range(2009, 2025):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/OKC/{i}.html\")\n",
    "        \n",
    "    #New Jersey Nets relocated in the 2013-2014 season to become the Brooklyn Nets\n",
    "    for i in range(2004, 2013):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/NJN/{i}.html\")\n",
    "    for i in range(2013, 2025):\n",
    "        teamLinks.append(f\"https://www.basketball-reference.com/teams/BRK/{i}.html\")\n",
    "\n",
    "\n",
    "    return teamLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f942ff-1217-4fa5-aeda-bb338c738c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "629984d0-eafd-4a23-a157-6b4bb0d2f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the NBA and ABA Players | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "await scrape_names() #get the page that contains the names of all the players who have been in the nba after for a certain last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39481db4-5661-427f-bf04-1bb6db1fab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n"
     ]
    }
   ],
   "source": [
    "#get the links of all the players \n",
    "NAMES_FILES = os.listdir(PLAYER_NAMES_DIR)\n",
    "playerLinks = []\n",
    "players_2004 = []\n",
    "for i in range(len(NAMES_FILES) -1):\n",
    "    #scrape the player links\n",
    "    [playerLinks.append(link) for link in scrape_table(i)]\n",
    "    [players_2004.append(link) for link in modified_scrape_table(i)]\n",
    "print(len(playerLinks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f41e0-e7e3-4e09-97b7-c79f89424784",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players_2004:\n",
    "    await scrape_career_stats(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619469c0-bad8-46b9-8afb-85eec190b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#allTeamLinks = []\n",
    "#scrape the data of every single player who joined the nba in the 2004 season to present day\n",
    "for player in playerLinks:\n",
    "    playerTeamLinks = await scrape_career_stats(player)\n",
    "    #if playerTeamLinks:\n",
    "    #   for team in playerTeamLinks:\n",
    "    #      [allTeamLinks.append(team) for team in playerTeamLinks if team not in allTeamLinks and '.html' in team] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a1ec07-0c81-4b06-a760-db70054a648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Team:  ATL2004.html\n",
      "Current Team:  ATL2005.html\n",
      "Current Team:  ATL2006.html\n",
      "Current Team:  ATL2007.html\n",
      "Current Team:  ATL2008.html\n",
      "Current Team:  ATL2009.html\n",
      "Current Team:  ATL2010.html\n",
      "Current Team:  ATL2011.html\n",
      "Current Team:  ATL2012.html\n",
      "Current Team:  ATL2013.html\n",
      "Current Team:  ATL2014.html\n",
      "Current Team:  ATL2015.html\n",
      "Current Team:  ATL2016.html\n",
      "Current Team:  ATL2017.html\n",
      "Current Team:  ATL2018.html\n",
      "Current Team:  ATL2019.html\n",
      "Current Team:  ATL2020.html\n",
      "Current Team:  ATL2021.html\n",
      "Current Team:  ATL2022.html\n",
      "Current Team:  ATL2023.html\n",
      "Current Team:  ATL2024.html\n",
      "Current Team:  BOS2004.html\n",
      "Current Team:  BOS2005.html\n",
      "Current Team:  BOS2006.html\n",
      "Current Team:  BOS2007.html\n",
      "Current Team:  BOS2008.html\n",
      "Current Team:  BOS2009.html\n",
      "Current Team:  BOS2010.html\n",
      "Current Team:  BOS2011.html\n",
      "Current Team:  BOS2012.html\n",
      "Current Team:  BOS2013.html\n",
      "Current Team:  BOS2014.html\n",
      "Current Team:  BOS2015.html\n",
      "Current Team:  BOS2016.html\n",
      "Current Team:  BOS2017.html\n",
      "Current Team:  BOS2018.html\n",
      "Current Team:  BOS2019.html\n",
      "Current Team:  BOS2020.html\n",
      "Current Team:  BOS2021.html\n",
      "Current Team:  BOS2022.html\n",
      "Current Team:  BOS2023.html\n",
      "Current Team:  BOS2024.html\n",
      "Current Team:  CHI2004.html\n",
      "Current Team:  CHI2005.html\n",
      "Current Team:  CHI2006.html\n",
      "Current Team:  CHI2007.html\n",
      "Current Team:  CHI2008.html\n",
      "Current Team:  CHI2009.html\n",
      "Current Team:  CHI2010.html\n",
      "Current Team:  CHI2011.html\n",
      "Current Team:  CHI2012.html\n",
      "Current Team:  CHI2013.html\n",
      "Current Team:  CHI2014.html\n",
      "Current Team:  CHI2015.html\n",
      "Current Team:  CHI2016.html\n",
      "Current Team:  CHI2017.html\n",
      "Current Team:  CHI2018.html\n",
      "Current Team:  CHI2019.html\n",
      "Current Team:  CHI2020.html\n",
      "Current Team:  CHI2021.html\n",
      "Current Team:  CHI2022.html\n",
      "Current Team:  CHI2023.html\n",
      "Current Team:  CHI2024.html\n",
      "Current Team:  CLE2004.html\n",
      "Current Team:  CLE2005.html\n",
      "Current Team:  CLE2006.html\n",
      "Current Team:  CLE2007.html\n",
      "Current Team:  CLE2008.html\n",
      "Current Team:  CLE2009.html\n",
      "Current Team:  CLE2010.html\n",
      "Current Team:  CLE2011.html\n",
      "Current Team:  CLE2012.html\n",
      "Current Team:  CLE2013.html\n",
      "Current Team:  CLE2014.html\n",
      "Current Team:  CLE2015.html\n",
      "Current Team:  CLE2016.html\n",
      "Current Team:  CLE2017.html\n",
      "Current Team:  CLE2018.html\n",
      "Current Team:  CLE2019.html\n",
      "Current Team:  CLE2020.html\n",
      "Current Team:  CLE2021.html\n",
      "Current Team:  CLE2022.html\n",
      "Current Team:  CLE2023.html\n",
      "Current Team:  CLE2024.html\n",
      "Current Team:  DAL2004.html\n",
      "Current Team:  DAL2005.html\n",
      "Current Team:  DAL2006.html\n",
      "Current Team:  DAL2007.html\n",
      "Current Team:  DAL2008.html\n",
      "Current Team:  DAL2009.html\n",
      "Current Team:  DAL2010.html\n",
      "Current Team:  DAL2011.html\n",
      "Current Team:  DAL2012.html\n",
      "Current Team:  DAL2013.html\n",
      "Current Team:  DAL2014.html\n",
      "Current Team:  DAL2015.html\n",
      "Current Team:  DAL2016.html\n",
      "Current Team:  DAL2017.html\n",
      "Current Team:  DAL2018.html\n",
      "Current Team:  DAL2019.html\n",
      "Current Team:  DAL2020.html\n",
      "Current Team:  DAL2021.html\n",
      "Current Team:  DAL2022.html\n",
      "Current Team:  DAL2023.html\n",
      "Current Team:  DAL2024.html\n",
      "Current Team:  DEN2004.html\n",
      "Current Team:  DEN2005.html\n",
      "Current Team:  DEN2006.html\n",
      "Current Team:  DEN2007.html\n",
      "Current Team:  DEN2008.html\n",
      "Current Team:  DEN2009.html\n",
      "Current Team:  DEN2010.html\n",
      "Current Team:  DEN2011.html\n",
      "Current Team:  DEN2012.html\n",
      "Current Team:  DEN2013.html\n",
      "Current Team:  DEN2014.html\n",
      "Current Team:  DEN2015.html\n",
      "Current Team:  DEN2016.html\n",
      "Current Team:  DEN2017.html\n",
      "Current Team:  DEN2018.html\n",
      "Current Team:  DEN2019.html\n",
      "Current Team:  DEN2020.html\n",
      "Current Team:  DEN2021.html\n",
      "Current Team:  DEN2022.html\n",
      "Current Team:  DEN2023.html\n",
      "Current Team:  DEN2024.html\n",
      "Current Team:  DET2004.html\n",
      "Current Team:  DET2005.html\n",
      "Current Team:  DET2006.html\n",
      "Current Team:  DET2007.html\n",
      "Current Team:  DET2008.html\n",
      "Current Team:  DET2009.html\n",
      "Current Team:  DET2010.html\n",
      "Current Team:  DET2011.html\n",
      "Current Team:  DET2012.html\n",
      "Current Team:  DET2013.html\n",
      "Current Team:  DET2014.html\n",
      "Current Team:  DET2015.html\n",
      "Current Team:  DET2016.html\n",
      "Current Team:  DET2017.html\n",
      "Current Team:  DET2018.html\n",
      "Current Team:  DET2019.html\n",
      "Current Team:  DET2020.html\n",
      "Current Team:  DET2021.html\n",
      "Current Team:  DET2022.html\n",
      "Current Team:  DET2023.html\n",
      "Current Team:  DET2024.html\n",
      "Current Team:  GSW2004.html\n",
      "Current Team:  GSW2005.html\n",
      "Current Team:  GSW2006.html\n",
      "Current Team:  GSW2007.html\n",
      "Current Team:  GSW2008.html\n",
      "Current Team:  GSW2009.html\n",
      "Current Team:  GSW2010.html\n",
      "Current Team:  GSW2011.html\n",
      "Current Team:  GSW2012.html\n",
      "Current Team:  GSW2013.html\n",
      "Current Team:  GSW2014.html\n",
      "Current Team:  GSW2015.html\n",
      "Current Team:  GSW2016.html\n",
      "Current Team:  GSW2017.html\n",
      "Current Team:  GSW2018.html\n",
      "Current Team:  GSW2019.html\n",
      "Current Team:  GSW2020.html\n",
      "Current Team:  GSW2021.html\n",
      "Current Team:  GSW2022.html\n",
      "Current Team:  GSW2023.html\n",
      "Current Team:  GSW2024.html\n",
      "Current Team:  HOU2004.html\n",
      "Current Team:  HOU2005.html\n",
      "Current Team:  HOU2006.html\n",
      "Current Team:  HOU2007.html\n",
      "Current Team:  HOU2008.html\n",
      "Current Team:  HOU2009.html\n",
      "Current Team:  HOU2010.html\n",
      "Current Team:  HOU2011.html\n",
      "Current Team:  HOU2012.html\n",
      "Current Team:  HOU2013.html\n",
      "Current Team:  HOU2014.html\n",
      "Current Team:  HOU2015.html\n",
      "Current Team:  HOU2016.html\n",
      "Current Team:  HOU2017.html\n",
      "Current Team:  HOU2018.html\n",
      "Current Team:  HOU2019.html\n",
      "Current Team:  HOU2020.html\n",
      "Current Team:  HOU2021.html\n",
      "Current Team:  HOU2022.html\n",
      "Current Team:  HOU2023.html\n",
      "Current Team:  HOU2024.html\n",
      "Current Team:  IND2004.html\n",
      "Current Team:  IND2005.html\n",
      "Current Team:  IND2006.html\n",
      "Current Team:  IND2007.html\n",
      "Current Team:  IND2008.html\n",
      "Current Team:  IND2009.html\n",
      "Current Team:  IND2010.html\n",
      "Current Team:  IND2011.html\n",
      "Current Team:  IND2012.html\n",
      "Current Team:  IND2013.html\n",
      "Current Team:  IND2014.html\n",
      "Current Team:  IND2015.html\n",
      "Current Team:  IND2016.html\n",
      "Current Team:  IND2017.html\n",
      "Current Team:  IND2018.html\n",
      "Current Team:  IND2019.html\n",
      "Current Team:  IND2020.html\n",
      "Current Team:  IND2021.html\n",
      "Current Team:  IND2022.html\n",
      "Current Team:  IND2023.html\n",
      "Current Team:  IND2024.html\n",
      "Current Team:  LAC2004.html\n",
      "Current Team:  LAC2005.html\n",
      "Current Team:  LAC2006.html\n",
      "Current Team:  LAC2007.html\n",
      "Current Team:  LAC2008.html\n",
      "Current Team:  LAC2009.html\n",
      "Current Team:  LAC2010.html\n",
      "Current Team:  LAC2011.html\n",
      "Current Team:  LAC2012.html\n",
      "Current Team:  LAC2013.html\n",
      "Current Team:  LAC2014.html\n",
      "Current Team:  LAC2015.html\n",
      "Current Team:  LAC2016.html\n",
      "Current Team:  LAC2017.html\n",
      "Current Team:  LAC2018.html\n",
      "Current Team:  LAC2019.html\n",
      "Current Team:  LAC2020.html\n",
      "Current Team:  LAC2021.html\n",
      "Current Team:  LAC2022.html\n",
      "Current Team:  LAC2023.html\n",
      "Current Team:  LAC2024.html\n",
      "Current Team:  LAL2004.html\n",
      "Current Team:  LAL2005.html\n",
      "Current Team:  LAL2006.html\n",
      "Current Team:  LAL2007.html\n",
      "Current Team:  LAL2008.html\n",
      "Current Team:  LAL2009.html\n",
      "Current Team:  LAL2010.html\n",
      "Current Team:  LAL2011.html\n",
      "Current Team:  LAL2012.html\n",
      "Current Team:  LAL2013.html\n",
      "Current Team:  LAL2014.html\n",
      "Current Team:  LAL2015.html\n",
      "Current Team:  LAL2016.html\n",
      "Current Team:  LAL2017.html\n",
      "Current Team:  LAL2018.html\n",
      "Current Team:  LAL2019.html\n",
      "Current Team:  LAL2020.html\n",
      "Current Team:  LAL2021.html\n",
      "Current Team:  LAL2022.html\n",
      "Current Team:  LAL2023.html\n",
      "Current Team:  LAL2024.html\n",
      "Current Team:  MEM2004.html\n",
      "Current Team:  MEM2005.html\n",
      "Current Team:  MEM2006.html\n",
      "Current Team:  MEM2007.html\n",
      "Current Team:  MEM2008.html\n",
      "Current Team:  MEM2009.html\n",
      "Current Team:  MEM2010.html\n",
      "Current Team:  MEM2011.html\n",
      "Current Team:  MEM2012.html\n",
      "Current Team:  MEM2013.html\n",
      "Current Team:  MEM2014.html\n",
      "Current Team:  MEM2015.html\n",
      "Current Team:  MEM2016.html\n",
      "Current Team:  MEM2017.html\n",
      "Current Team:  MEM2018.html\n",
      "Current Team:  MEM2019.html\n",
      "Current Team:  MEM2020.html\n",
      "Current Team:  MEM2021.html\n",
      "Current Team:  MEM2022.html\n",
      "Current Team:  MEM2023.html\n",
      "Current Team:  MEM2024.html\n",
      "Current Team:  MIA2004.html\n",
      "Current Team:  MIA2005.html\n",
      "Current Team:  MIA2006.html\n",
      "Current Team:  MIA2007.html\n",
      "Current Team:  MIA2008.html\n",
      "Current Team:  MIA2009.html\n",
      "Current Team:  MIA2010.html\n",
      "Current Team:  MIA2011.html\n",
      "Current Team:  MIA2012.html\n",
      "Current Team:  MIA2013.html\n",
      "Current Team:  MIA2014.html\n",
      "Current Team:  MIA2015.html\n",
      "Current Team:  MIA2016.html\n",
      "Current Team:  MIA2017.html\n",
      "Current Team:  MIA2018.html\n",
      "Current Team:  MIA2019.html\n",
      "Current Team:  MIA2020.html\n",
      "Current Team:  MIA2021.html\n",
      "Current Team:  MIA2022.html\n",
      "Current Team:  MIA2023.html\n",
      "Current Team:  MIA2024.html\n",
      "Current Team:  MIL2004.html\n",
      "Current Team:  MIL2005.html\n",
      "Current Team:  MIL2006.html\n",
      "Current Team:  MIL2007.html\n",
      "Current Team:  MIL2008.html\n",
      "Current Team:  MIL2009.html\n",
      "Current Team:  MIL2010.html\n",
      "Current Team:  MIL2011.html\n",
      "Current Team:  MIL2012.html\n",
      "Current Team:  MIL2013.html\n",
      "Current Team:  MIL2014.html\n",
      "Current Team:  MIL2015.html\n",
      "Current Team:  MIL2016.html\n",
      "Current Team:  MIL2017.html\n",
      "Current Team:  MIL2018.html\n",
      "Current Team:  MIL2019.html\n",
      "Current Team:  MIL2020.html\n",
      "Current Team:  MIL2021.html\n",
      "Current Team:  MIL2022.html\n",
      "Current Team:  MIL2023.html\n",
      "Current Team:  MIL2024.html\n",
      "Current Team:  MIN2004.html\n",
      "Current Team:  MIN2005.html\n",
      "Current Team:  MIN2006.html\n",
      "Current Team:  MIN2007.html\n",
      "Current Team:  MIN2008.html\n",
      "Current Team:  MIN2009.html\n",
      "Current Team:  MIN2010.html\n",
      "Current Team:  MIN2011.html\n",
      "Current Team:  MIN2012.html\n",
      "Current Team:  MIN2013.html\n",
      "Current Team:  MIN2014.html\n",
      "Current Team:  MIN2015.html\n",
      "Current Team:  MIN2016.html\n",
      "Current Team:  MIN2017.html\n",
      "Current Team:  MIN2018.html\n",
      "Current Team:  MIN2019.html\n",
      "Current Team:  MIN2020.html\n",
      "Current Team:  MIN2021.html\n",
      "Current Team:  MIN2022.html\n",
      "Current Team:  MIN2023.html\n",
      "Current Team:  MIN2024.html\n",
      "Current Team:  NYK2004.html\n",
      "Current Team:  NYK2005.html\n",
      "Current Team:  NYK2006.html\n",
      "Current Team:  NYK2007.html\n",
      "Current Team:  NYK2008.html\n",
      "Current Team:  NYK2009.html\n",
      "Current Team:  NYK2010.html\n",
      "Current Team:  NYK2011.html\n",
      "Current Team:  NYK2012.html\n",
      "Current Team:  NYK2013.html\n",
      "Current Team:  NYK2014.html\n",
      "Current Team:  NYK2015.html\n",
      "Current Team:  NYK2016.html\n",
      "Current Team:  NYK2017.html\n",
      "Current Team:  NYK2018.html\n",
      "Current Team:  NYK2019.html\n",
      "Current Team:  NYK2020.html\n",
      "Current Team:  NYK2021.html\n",
      "Current Team:  NYK2022.html\n",
      "Current Team:  NYK2023.html\n",
      "Current Team:  NYK2024.html\n",
      "Current Team:  ORL2004.html\n",
      "Current Team:  ORL2005.html\n",
      "Current Team:  ORL2006.html\n",
      "Current Team:  ORL2007.html\n",
      "Current Team:  ORL2008.html\n",
      "Current Team:  ORL2009.html\n",
      "Current Team:  ORL2010.html\n",
      "Current Team:  ORL2011.html\n",
      "Current Team:  ORL2012.html\n",
      "Current Team:  ORL2013.html\n",
      "Current Team:  ORL2014.html\n",
      "Current Team:  ORL2015.html\n",
      "Current Team:  ORL2016.html\n",
      "Current Team:  ORL2017.html\n",
      "Current Team:  ORL2018.html\n",
      "Current Team:  ORL2019.html\n",
      "Current Team:  ORL2020.html\n",
      "Current Team:  ORL2021.html\n",
      "Current Team:  ORL2022.html\n",
      "Current Team:  ORL2023.html\n",
      "Current Team:  ORL2024.html\n",
      "Current Team:  PHI2004.html\n",
      "Current Team:  PHI2005.html\n",
      "Current Team:  PHI2006.html\n",
      "Current Team:  PHI2007.html\n",
      "Current Team:  PHI2008.html\n",
      "Current Team:  PHI2009.html\n",
      "Current Team:  PHI2010.html\n",
      "Current Team:  PHI2011.html\n",
      "Current Team:  PHI2012.html\n",
      "Current Team:  PHI2013.html\n",
      "Current Team:  PHI2014.html\n",
      "Current Team:  PHI2015.html\n",
      "Current Team:  PHI2016.html\n",
      "Current Team:  PHI2017.html\n",
      "Current Team:  PHI2018.html\n",
      "Current Team:  PHI2019.html\n",
      "Current Team:  PHI2020.html\n",
      "Current Team:  PHI2021.html\n",
      "Current Team:  PHI2022.html\n",
      "Current Team:  PHI2023.html\n",
      "Current Team:  PHI2024.html\n",
      "Current Team:  PHO2004.html\n",
      "Current Team:  PHO2005.html\n",
      "Current Team:  PHO2006.html\n",
      "Current Team:  PHO2007.html\n",
      "Current Team:  PHO2008.html\n",
      "Current Team:  PHO2009.html\n",
      "Current Team:  PHO2010.html\n",
      "Current Team:  PHO2011.html\n",
      "Current Team:  PHO2012.html\n",
      "Current Team:  PHO2013.html\n",
      "Current Team:  PHO2014.html\n",
      "Current Team:  PHO2015.html\n",
      "Current Team:  PHO2016.html\n",
      "Current Team:  PHO2017.html\n",
      "Current Team:  PHO2018.html\n",
      "Current Team:  PHO2019.html\n",
      "Current Team:  PHO2020.html\n",
      "Current Team:  PHO2021.html\n",
      "Current Team:  PHO2022.html\n",
      "Current Team:  PHO2023.html\n",
      "Current Team:  PHO2024.html\n",
      "Current Team:  POR2004.html\n",
      "Current Team:  POR2005.html\n",
      "Current Team:  POR2006.html\n",
      "Current Team:  POR2007.html\n",
      "Current Team:  POR2008.html\n",
      "Current Team:  POR2009.html\n",
      "Current Team:  POR2010.html\n",
      "Current Team:  POR2011.html\n",
      "Current Team:  POR2012.html\n",
      "Current Team:  POR2013.html\n",
      "Current Team:  POR2014.html\n",
      "Current Team:  POR2015.html\n",
      "Current Team:  POR2016.html\n",
      "Current Team:  POR2017.html\n",
      "Current Team:  POR2018.html\n",
      "Current Team:  POR2019.html\n",
      "Current Team:  POR2020.html\n",
      "Current Team:  POR2021.html\n",
      "Current Team:  POR2022.html\n",
      "Current Team:  POR2023.html\n",
      "Current Team:  POR2024.html\n",
      "Current Team:  SAC2004.html\n",
      "Current Team:  SAC2005.html\n",
      "Current Team:  SAC2006.html\n",
      "Current Team:  SAC2007.html\n",
      "Current Team:  SAC2008.html\n",
      "Current Team:  SAC2009.html\n",
      "Current Team:  SAC2010.html\n",
      "Current Team:  SAC2011.html\n",
      "Current Team:  SAC2012.html\n",
      "Current Team:  SAC2013.html\n",
      "Current Team:  SAC2014.html\n",
      "Current Team:  SAC2015.html\n",
      "Current Team:  SAC2016.html\n",
      "Current Team:  SAC2017.html\n",
      "Current Team:  SAC2018.html\n",
      "Current Team:  SAC2019.html\n",
      "Current Team:  SAC2020.html\n",
      "Current Team:  SAC2021.html\n",
      "Current Team:  SAC2022.html\n",
      "Current Team:  SAC2023.html\n",
      "Current Team:  SAC2024.html\n",
      "Current Team:  SAS2004.html\n",
      "Current Team:  SAS2005.html\n",
      "Current Team:  SAS2006.html\n",
      "Current Team:  SAS2007.html\n",
      "Current Team:  SAS2008.html\n",
      "Current Team:  SAS2009.html\n",
      "Current Team:  SAS2010.html\n",
      "Current Team:  SAS2011.html\n",
      "Current Team:  SAS2012.html\n",
      "Current Team:  SAS2013.html\n",
      "Current Team:  SAS2014.html\n",
      "Current Team:  SAS2015.html\n",
      "Current Team:  SAS2016.html\n",
      "Current Team:  SAS2017.html\n",
      "Current Team:  SAS2018.html\n",
      "Current Team:  SAS2019.html\n",
      "Current Team:  SAS2020.html\n",
      "Current Team:  SAS2021.html\n",
      "Current Team:  SAS2022.html\n",
      "Current Team:  SAS2023.html\n",
      "Current Team:  SAS2024.html\n",
      "Current Team:  TOR2004.html\n",
      "Current Team:  TOR2005.html\n",
      "Current Team:  TOR2006.html\n",
      "Current Team:  TOR2007.html\n",
      "Current Team:  TOR2008.html\n",
      "Current Team:  TOR2009.html\n",
      "Current Team:  TOR2010.html\n",
      "Current Team:  TOR2011.html\n",
      "Current Team:  TOR2012.html\n",
      "Current Team:  TOR2013.html\n",
      "Current Team:  TOR2014.html\n",
      "Current Team:  TOR2015.html\n",
      "Current Team:  TOR2016.html\n",
      "Current Team:  TOR2017.html\n",
      "Current Team:  TOR2018.html\n",
      "Current Team:  TOR2019.html\n",
      "Current Team:  TOR2020.html\n",
      "Current Team:  TOR2021.html\n",
      "Current Team:  TOR2022.html\n",
      "Current Team:  TOR2023.html\n",
      "Current Team:  TOR2024.html\n",
      "Current Team:  UTA2004.html\n",
      "Current Team:  UTA2005.html\n",
      "Current Team:  UTA2006.html\n",
      "Current Team:  UTA2007.html\n",
      "Current Team:  UTA2008.html\n",
      "Current Team:  UTA2009.html\n",
      "Current Team:  UTA2010.html\n",
      "Current Team:  UTA2011.html\n",
      "Current Team:  UTA2012.html\n",
      "Current Team:  UTA2013.html\n",
      "Current Team:  UTA2014.html\n",
      "Current Team:  UTA2015.html\n",
      "Current Team:  UTA2016.html\n",
      "Current Team:  UTA2017.html\n",
      "Current Team:  UTA2018.html\n",
      "Current Team:  UTA2019.html\n",
      "Current Team:  UTA2020.html\n",
      "Current Team:  UTA2021.html\n",
      "Current Team:  UTA2022.html\n",
      "Current Team:  UTA2023.html\n",
      "Current Team:  UTA2024.html\n",
      "Current Team:  WAS2004.html\n",
      "Current Team:  WAS2005.html\n",
      "Current Team:  WAS2006.html\n",
      "Current Team:  WAS2007.html\n",
      "Current Team:  WAS2008.html\n",
      "Current Team:  WAS2009.html\n",
      "Current Team:  WAS2010.html\n",
      "Current Team:  WAS2011.html\n",
      "Current Team:  WAS2012.html\n",
      "Current Team:  WAS2013.html\n",
      "Current Team:  WAS2014.html\n",
      "Current Team:  WAS2015.html\n",
      "Current Team:  WAS2016.html\n",
      "Current Team:  WAS2017.html\n",
      "Current Team:  WAS2018.html\n",
      "Current Team:  WAS2019.html\n",
      "Current Team:  WAS2020.html\n",
      "Current Team:  WAS2021.html\n",
      "Current Team:  WAS2022.html\n",
      "Current Team:  WAS2023.html\n",
      "Current Team:  WAS2024.html\n",
      "Current Team:  CHA2004.html\n",
      "Current Team:  CHA2005.html\n",
      "Current Team:  CHA2006.html\n",
      "Current Team:  CHA2007.html\n",
      "Current Team:  CHA2008.html\n",
      "Current Team:  CHA2009.html\n",
      "Current Team:  CHA2010.html\n",
      "Current Team:  CHA2011.html\n",
      "Current Team:  CHA2012.html\n",
      "Current Team:  CHA2013.html\n",
      "Current Team:  CHA2014.html\n",
      "2013-14 Charlotte Bobcats Roster and Stats | Basketball-Reference.com\n",
      "Current Team:  CHO2015.html\n",
      "Current Team:  CHO2016.html\n",
      "Current Team:  CHO2017.html\n",
      "Current Team:  CHO2018.html\n",
      "Current Team:  CHO2019.html\n",
      "Current Team:  CHO2020.html\n",
      "Current Team:  CHO2021.html\n",
      "Current Team:  CHO2022.html\n",
      "Current Team:  CHO2023.html\n",
      "Current Team:  CHO2024.html\n",
      "Current Team:  NOH2004.html\n",
      "Current Team:  NOH2005.html\n",
      "Current Team:  NOH2006.html\n",
      "Current Team:  NOH2007.html\n",
      "Current Team:  NOH2008.html\n",
      "Current Team:  NOH2009.html\n",
      "Current Team:  NOH2010.html\n",
      "Current Team:  NOH2011.html\n",
      "Current Team:  NOH2012.html\n",
      "Current Team:  NOH2013.html\n",
      "Current Team:  NOK2006.html\n",
      "Current Team:  NOK2007.html\n",
      "Current Team:  NOP2014.html\n",
      "Current Team:  NOP2015.html\n",
      "Current Team:  NOP2016.html\n",
      "Current Team:  NOP2017.html\n",
      "Current Team:  NOP2018.html\n",
      "Current Team:  NOP2019.html\n",
      "Current Team:  NOP2020.html\n",
      "Current Team:  NOP2021.html\n",
      "Current Team:  NOP2022.html\n",
      "Current Team:  NOP2023.html\n",
      "Current Team:  NOP2024.html\n",
      "Current Team:  SEA2004.html\n",
      "Current Team:  SEA2005.html\n",
      "Current Team:  SEA2006.html\n",
      "Current Team:  SEA2007.html\n",
      "Current Team:  SEA2008.html\n",
      "Current Team:  OKC2009.html\n",
      "Current Team:  OKC2010.html\n",
      "Current Team:  OKC2011.html\n",
      "Current Team:  OKC2012.html\n",
      "Current Team:  OKC2013.html\n",
      "Current Team:  OKC2014.html\n",
      "Current Team:  OKC2015.html\n",
      "Current Team:  OKC2016.html\n",
      "Current Team:  OKC2017.html\n",
      "Current Team:  OKC2018.html\n",
      "Current Team:  OKC2019.html\n",
      "Current Team:  OKC2020.html\n",
      "Current Team:  OKC2021.html\n",
      "Current Team:  OKC2022.html\n",
      "Current Team:  OKC2023.html\n",
      "Current Team:  OKC2024.html\n",
      "Current Team:  NJN2004.html\n",
      "Current Team:  NJN2005.html\n",
      "Current Team:  NJN2006.html\n",
      "Current Team:  NJN2007.html\n",
      "Current Team:  NJN2008.html\n",
      "Current Team:  NJN2009.html\n",
      "Current Team:  NJN2010.html\n",
      "Current Team:  NJN2011.html\n",
      "Current Team:  NJN2012.html\n",
      "Current Team:  BRK2013.html\n",
      "Current Team:  BRK2014.html\n",
      "Current Team:  BRK2015.html\n",
      "Current Team:  BRK2016.html\n",
      "Current Team:  BRK2017.html\n",
      "Current Team:  BRK2018.html\n",
      "Current Team:  BRK2019.html\n",
      "Current Team:  BRK2020.html\n",
      "Current Team:  BRK2021.html\n",
      "Current Team:  BRK2022.html\n",
      "Current Team:  BRK2023.html\n",
      "Current Team:  BRK2024.html\n"
     ]
    }
   ],
   "source": [
    "#Get the link of all the nba teams\n",
    "allNBATeamsLinks = get_NBA_team_link()\n",
    "#boolean flag to ensure we get the data for all teams (sometimes random failure occurs)\n",
    "completedTeams = True\n",
    "#conditional loop\n",
    "while completedTeams:\n",
    "    completedTeams = True\n",
    "    #for each link scrape the data\n",
    "    for link in allNBATeamsLinks:\n",
    "        #if an element was already completed prevCompleted is set to True, else, it is False\n",
    "        prevCompleted = await scrape_nba_team_stats(link)\n",
    "        #if prevCompleted is ever flase, then set completedTeams to False, so it goes through the loop again\n",
    "        if not prevCompleted:\n",
    "            completedTeams = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903aa4e5-3305-4084-aac5-577ac2c5d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PALYER_STATS_FILE = os.listdir(PLAYER_STATS_2_DIR)\n",
    "len(PALYER_STATS_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
